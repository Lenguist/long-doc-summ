{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nto implement:\\nR-1, R-2, R-L, BERTScore, METEOR\\nAutomatic metrics to compare against previous papers\\nSNaC for coherence\\nFull code in this repo https://github.com/tagoyal/snac\\nShould be easy to run their T5 models unless I’m retraining\\nQAFactEval for faithfulness\\nFull code in this repo https://github.com/salesforce/QAFactEval#using-qafacteval\\nShould be easy to run but not tested for my domain\\nNeed automatic metric for coverage\\nAI-eval\\nJust ask GPT-4 the same questions as to the humans\\nSee what Faisal is doing with this\\nhttps://arxiv.org/pdf/2305.17926.pdf\\nHuman-eval\\nIs the summary correct relative to the passage?\\nDoes the summary cover the important events?\\nIs the summary well-written and coherent?\\nPreference relative to baseline summary\\nWriting class will evaluate summaries of their own work\\nAdd interpretation here\\nWhat do we want to get out of the eval? Have this drive the approach\\nStrategies from here https://arxiv.org/pdf/2301.13298.pdf\\nError analysis on low quality summaries\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running different evaluations for long-doc-summ\n",
    "\n",
    "ssh mb5018@branzino.cs.columbia.edu\n",
    "\"\"\"\n",
    "to implement:\n",
    "R-1, R-2, R-L, BERTScore, METEOR\n",
    "Automatic metrics to compare against previous papers\n",
    "SNaC for coherence\n",
    "Full code in this repo https://github.com/tagoyal/snac\n",
    "Should be easy to run their T5 models unless I’m retraining\n",
    "QAFactEval for faithfulness\n",
    "Full code in this repo https://github.com/salesforce/QAFactEval#using-qafacteval\n",
    "Should be easy to run but not tested for my domain\n",
    "Need automatic metric for coverage\n",
    "AI-eval\n",
    "Just ask GPT-4 the same questions as to the humans\n",
    "See what Faisal is doing with this\n",
    "https://arxiv.org/pdf/2305.17926.pdf\n",
    "Human-eval\n",
    "Is the summary correct relative to the passage?\n",
    "Does the summary cover the important events?\n",
    "Is the summary well-written and coherent?\n",
    "Preference relative to baseline summary\n",
    "Writing class will evaluate summaries of their own work\n",
    "Add interpretation here\n",
    "What do we want to get out of the eval? Have this drive the approach\n",
    "Strategies from here https://arxiv.org/pdf/2301.13298.pdf\n",
    "Error analysis on low quality summaries\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path = \"booksumm-sample2/what-maisie-knew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(orig_path+\"/metadata.json\") as f:\n",
    "  book_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'What Maisie Knew',\n",
       " 'author': 'Henry James',\n",
       " 'total-chapters': 31,\n",
       " 'average-chapter-len': 4256.935483870968,\n",
       " 'dir': '7118-chapters'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maisie has to go back to her father and Miss Overmore . This means that she has to say goodbye to Mrs. Wix for the first time, and this is super, super sad! Maisie asks her father if he liked Miss Overmore \"just the same\" while she was at her mother\\'s . This embarrasses Miss Overmore, even though Beale Farange makes no secret of having been with Miss Overmore the whole time. This is just above Maisie\\'s head. She, too, feels embarrassed and wonders why Miss Overmore has been awkward. She also tries to figure out the nature of her father\\'s relationship to Miss Overmore. Maisie takes to treating her doll, Lisette, the way she herself is treated by her mother and Miss Overmore. She keeps secrets from her doll and even reprimands her for asking indiscreet questions.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory paths\n",
    "dir_path1 = \"booksumm-sample2/what-maisie-knew\"\n",
    "dir_path2 = \"gpt4_summaries/what-maisie-knew\"\n",
    "\n",
    "# Define the data structure\n",
    "data = {\n",
    "    \"subdir\": [],\n",
    "    \"metadata\": [],\n",
    "    \"content\": [],\n",
    "    \"summaries\": [],\n",
    "    \"new_summary\": []\n",
    "}\n",
    "\n",
    "# Loop over subdirectories\n",
    "for subdir in os.listdir(dir_path1):\n",
    "    subdir_path1 = os.path.join(dir_path1, subdir)\n",
    "\n",
    "    # If the path is a directory, process it\n",
    "    if os.path.isdir(subdir_path1):\n",
    "        data[\"subdir\"].append(subdir)\n",
    "\n",
    "        # Process metadata.json\n",
    "        with open(os.path.join(subdir_path1, \"metadata.json\"), 'r') as f:\n",
    "            data[\"metadata\"].append(json.load(f))\n",
    "\n",
    "        # Process content.txt\n",
    "        with open(os.path.join(subdir_path1, \"content.txt\"), 'r') as f:\n",
    "            data[\"content\"].append(f.read())\n",
    "\n",
    "        # Process summaries\n",
    "        summaries = []\n",
    "        for file in os.listdir(subdir_path1):\n",
    "            if file.endswith(\"summary.txt\"):\n",
    "                with open(os.path.join(subdir_path1, file), 'r') as f:\n",
    "                    content = f.read()\n",
    "                    summaries.append(content)\n",
    "        data[\"summaries\"].append(summaries)\n",
    "\n",
    "        # Process new directory\n",
    "        subdir_path2 = os.path.join(dir_path2, subdir)\n",
    "        if os.path.isdir(subdir_path2):\n",
    "            with open(os.path.join(subdir_path2, \"summary.txt\"), 'r') as f:\n",
    "                data[\"new_summary\"].append(f.read())\n",
    "        else:\n",
    "            data[\"new_summary\"].append(None)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index('subdir')  # Set index to subdirectory names\n",
    "\n",
    "\n",
    "json.loads(df['summaries'][0][0])[\"summary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>content</th>\n",
       "      <th>summaries</th>\n",
       "      <th>new_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdir</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '05...</td>\n",
       "      <td>\\n\\nThe second parting from Miss Overmore had ...</td>\n",
       "      <td>[{\"name\": \"Chapter V\", \"url\": \"https://web.arc...</td>\n",
       "      <td>This chapter revolves around a young girl name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '21...</td>\n",
       "      <td>\\n\\nA good deal of the rest of Ida's visit was...</td>\n",
       "      <td>[{\"name\": \"Chapter XXI\", \"url\": \"https://web.a...</td>\n",
       "      <td>In this chapter, Maisie and her mother, Ida, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '30...</td>\n",
       "      <td>\\n\\nAfter they were seated there it was differ...</td>\n",
       "      <td>[{\"name\": \"Chapter XXX\", \"url\": \"https://web.a...</td>\n",
       "      <td>In this chapter, Sir Claude and Maisie have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '23...</td>\n",
       "      <td>\\n\\nSir Claude was stationed at the window; he...</td>\n",
       "      <td>[{\"name\": \"Chapter XXIII\", \"url\": \"https://web...</td>\n",
       "      <td>In this chapter, Mrs. Wix, Sir Claude, and Mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '14...</td>\n",
       "      <td>\\n\\nMrs Beale fairly swooped upon her and the ...</td>\n",
       "      <td>[{\"name\": \"Chapter XIV\", \"url\": \"https://web.a...</td>\n",
       "      <td>In this chapter, Maisie is reunited with her s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 metadata  \\\n",
       "subdir                                                      \n",
       "05      {'book-id': '7118-chapters', 'chapter-id': '05...   \n",
       "21      {'book-id': '7118-chapters', 'chapter-id': '21...   \n",
       "30      {'book-id': '7118-chapters', 'chapter-id': '30...   \n",
       "23      {'book-id': '7118-chapters', 'chapter-id': '23...   \n",
       "14      {'book-id': '7118-chapters', 'chapter-id': '14...   \n",
       "\n",
       "                                                  content  \\\n",
       "subdir                                                      \n",
       "05      \\n\\nThe second parting from Miss Overmore had ...   \n",
       "21      \\n\\nA good deal of the rest of Ida's visit was...   \n",
       "30      \\n\\nAfter they were seated there it was differ...   \n",
       "23      \\n\\nSir Claude was stationed at the window; he...   \n",
       "14      \\n\\nMrs Beale fairly swooped upon her and the ...   \n",
       "\n",
       "                                                summaries  \\\n",
       "subdir                                                      \n",
       "05      [{\"name\": \"Chapter V\", \"url\": \"https://web.arc...   \n",
       "21      [{\"name\": \"Chapter XXI\", \"url\": \"https://web.a...   \n",
       "30      [{\"name\": \"Chapter XXX\", \"url\": \"https://web.a...   \n",
       "23      [{\"name\": \"Chapter XXIII\", \"url\": \"https://web...   \n",
       "14      [{\"name\": \"Chapter XIV\", \"url\": \"https://web.a...   \n",
       "\n",
       "                                              new_summary  \n",
       "subdir                                                     \n",
       "05      This chapter revolves around a young girl name...  \n",
       "21      In this chapter, Maisie and her mother, Ida, s...  \n",
       "30      In this chapter, Sir Claude and Maisie have a ...  \n",
       "23      In this chapter, Mrs. Wix, Sir Claude, and Mai...  \n",
       "14      In this chapter, Maisie is reunited with her s...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_summary(summary_list):\n",
    "  new_list = []\n",
    "  for summary in summary_list:\n",
    "    out = json.loads(summary)[\"summary\"]\n",
    "    new_list.append(out)\n",
    "  return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"summaries\"] = df['summaries'].apply(process_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>content</th>\n",
       "      <th>summaries</th>\n",
       "      <th>new_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdir</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '05...</td>\n",
       "      <td>\\n\\nThe second parting from Miss Overmore had ...</td>\n",
       "      <td>[Maisie has to go back to her father and Miss ...</td>\n",
       "      <td>This chapter revolves around a young girl name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '21...</td>\n",
       "      <td>\\n\\nA good deal of the rest of Ida's visit was...</td>\n",
       "      <td>[Ida and Maisie have a heart-to-heart. Ida is ...</td>\n",
       "      <td>In this chapter, Maisie and her mother, Ida, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '30...</td>\n",
       "      <td>\\n\\nAfter they were seated there it was differ...</td>\n",
       "      <td>[Maisie's cafe trip with Sir Claude turns into...</td>\n",
       "      <td>In this chapter, Sir Claude and Maisie have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '23...</td>\n",
       "      <td>\\n\\nSir Claude was stationed at the window; he...</td>\n",
       "      <td>[Mrs. Wix says that she has seen Maisie's moth...</td>\n",
       "      <td>In this chapter, Mrs. Wix, Sir Claude, and Mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '14...</td>\n",
       "      <td>\\n\\nMrs Beale fairly swooped upon her and the ...</td>\n",
       "      <td>[Mrs. Beale lets it slip that she and Sir Clau...</td>\n",
       "      <td>In this chapter, Maisie is reunited with her s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 metadata  \\\n",
       "subdir                                                      \n",
       "05      {'book-id': '7118-chapters', 'chapter-id': '05...   \n",
       "21      {'book-id': '7118-chapters', 'chapter-id': '21...   \n",
       "30      {'book-id': '7118-chapters', 'chapter-id': '30...   \n",
       "23      {'book-id': '7118-chapters', 'chapter-id': '23...   \n",
       "14      {'book-id': '7118-chapters', 'chapter-id': '14...   \n",
       "\n",
       "                                                  content  \\\n",
       "subdir                                                      \n",
       "05      \\n\\nThe second parting from Miss Overmore had ...   \n",
       "21      \\n\\nA good deal of the rest of Ida's visit was...   \n",
       "30      \\n\\nAfter they were seated there it was differ...   \n",
       "23      \\n\\nSir Claude was stationed at the window; he...   \n",
       "14      \\n\\nMrs Beale fairly swooped upon her and the ...   \n",
       "\n",
       "                                                summaries  \\\n",
       "subdir                                                      \n",
       "05      [Maisie has to go back to her father and Miss ...   \n",
       "21      [Ida and Maisie have a heart-to-heart. Ida is ...   \n",
       "30      [Maisie's cafe trip with Sir Claude turns into...   \n",
       "23      [Mrs. Wix says that she has seen Maisie's moth...   \n",
       "14      [Mrs. Beale lets it slip that she and Sir Clau...   \n",
       "\n",
       "                                              new_summary  \n",
       "subdir                                                     \n",
       "05      This chapter revolves around a young girl name...  \n",
       "21      In this chapter, Maisie and her mother, Ida, s...  \n",
       "30      In this chapter, Sir Claude and Maisie have a ...  \n",
       "23      In this chapter, Mrs. Wix, Sir Claude, and Mai...  \n",
       "14      In this chapter, Maisie is reunited with her s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (1.24.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge_score\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mbondarenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mbondarenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/mbondarenko/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.41354723707664887, 'rouge2': 0.11091234347048301, 'rougeL': 0.19576719576719573, 'rougeLsum': 0.25396825396825395}\n",
      "{'meteor': 0.35806239548866164}\n",
      "{'precision': [0.7972561120986938], 'recall': [0.8193682432174683], 'f1': [0.7973999381065369], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=3.0.2)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = [df[\"new_summary\"][0]]\n",
    "references = [df[\"summaries\"][0]]\n",
    "print(rouge.compute(predictions=predictions,references=references))\n",
    "print(meteor.compute(predictions=predictions,references=references))\n",
    "print(bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.7972561120986938], 'recall': [0.8193682432174683], 'f1': [0.7973999381065369], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=3.0.2)'}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_folder = \"/Users/mbondarenko/Desktop/long-doc-summ/QAFactEval/models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch.backends' has no attribute 'mps'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39;49mbackends\u001b[39m.\u001b[39;49mmps\u001b[39m.\u001b[39mis_available()) \u001b[39m#the MacOS is higher than 12.3+\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(torch\u001b[39m.\u001b[39mbackends\u001b[39m.\u001b[39mmps\u001b[39m.\u001b[39mis_built()) \u001b[39m#MPS is activated\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch.backends' has no attribute 'mps'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "\n",
    "print(torch.backends.mps.is_available()) #the MacOS is higher than 12.3+\n",
    "print(torch.backends.mps.is_built()) #MPS is activated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (1.6.0)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.15.2-cp38-cp38-macosx_10_9_x86_64.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchaudio\n",
      "  Downloading torchaudio-2.0.2-cp38-cp38-macosx_10_9_x86_64.whl (3.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: future in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (0.18.3)\n",
      "Requirement already satisfied: numpy in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (1.24.4)\n",
      "Requirement already satisfied: requests in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torchvision) (2.31.0)\n",
      "Collecting torch\n",
      "  Using cached torch-2.0.1-cp38-none-macosx_10_9_x86_64.whl (143.1 MB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torchvision) (10.0.0)\n",
      "Requirement already satisfied: filelock in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (3.0.12)\n",
      "Requirement already satisfied: typing-extensions in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests->torchvision) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests->torchvision) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests->torchvision) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from sympy->torch) (1.3.0)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.6.0\n",
      "    Uninstalling torch-1.6.0:\n",
      "      Successfully uninstalled torch-1.6.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "allennlp 1.1.0 requires torch<1.7.0,>=1.6.0, but you have torch 2.0.1 which is incompatible.\n",
      "qaeval 0.1.0 requires torch==1.6.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed torch-2.0.1 torchaudio-2.0.2 torchvision-0.15.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: 100%|██████████| 1.52k/1.52k [00:00<00:00, 1.59MB/s]\n",
      "Downloading: 100%|██████████| 1.02G/1.02G [01:06<00:00, 15.3MB/s]\n",
      "WARNING:transformers.modeling_utils:Some weights of BartForConditionalGeneration were not initialized from the model checkpoint at facebook/bart-large and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Downloading: 100%|██████████| 899k/899k [00:00<00:00, 10.4MB/s]\n",
      "Downloading: 100%|██████████| 456k/456k [00:00<00:00, 8.05MB/s]\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcuda_device\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muse_lerc_quip\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \\\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mgeneration_batch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m32\u001b[39m, \\\n\u001b[1;32m      4\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39manswering_batch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m32\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlerc_batch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m8\u001b[39m}\n\u001b[1;32m      6\u001b[0m model_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# path to models downloaded with download_models.sh\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m metric \u001b[39m=\u001b[39m QAFactEval(\n\u001b[1;32m      8\u001b[0m     lerc_quip_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/quip-512-mocha\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     generation_model_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/Users/mbondarenko/Desktop/long-doc-summ/QAFactEval/models/generation/model.tar.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     answering_model_dir\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/answering\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     lerc_model_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/lerc/model.tar.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     lerc_pretrained_model_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/lerc/pretraining.tar.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m results \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mscore_batch_qafacteval([\u001b[39m\"\u001b[39m\u001b[39mThis is a source document\u001b[39m\u001b[39m\"\u001b[39m], [[\u001b[39m\"\u001b[39m\u001b[39mThis is a summary.\u001b[39m\u001b[39m\"\u001b[39m]], return_qa_pairs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m score \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mqa-eval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlerc_quip\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/long-doc-summ/QAFactEval/qafacteval.py:46\u001b[0m, in \u001b[0;36mQAFactEval.__init__\u001b[0;34m(self, lerc_quip_path, use_lerc_quip, lerc_batch_size, cuda_device, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcli\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     spacy\u001b[39m.\u001b[39mcli\u001b[39m.\u001b[39mdownload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(cuda_device\u001b[39m=\u001b[39;49mcuda_device, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m use_lerc_quip:\n\u001b[1;32m     49\u001b[0m     lerc_quip \u001b[39m=\u001b[39m LERCQuipScorer(lerc_quip_path\u001b[39m=\u001b[39mlerc_quip_path, \\\n\u001b[1;32m     50\u001b[0m         cuda_device\u001b[39m=\u001b[39mcuda_device, batch_size\u001b[39m=\u001b[39mlerc_batch_size)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/qaeval/metric.py:38\u001b[0m, in \u001b[0;36mQAEval.__init__\u001b[0;34m(self, generation_model_path, answering_model_dir, answer_selection_strategy, cuda_device, generation_batch_size, answering_batch_size, use_lerc, lerc_model_path, lerc_pretrained_model_path, lerc_batch_size, verbose)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     25\u001b[0m     generation_model_path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manswer_selector \u001b[39m=\u001b[39m AnswerSelector(answer_selection_strategy)\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquestion_generator \u001b[39m=\u001b[39m QuestionGenerationModel(\n\u001b[1;32m     39\u001b[0m         generation_model_path,\n\u001b[1;32m     40\u001b[0m         cuda_device\u001b[39m=\u001b[39;49mcuda_device,\n\u001b[1;32m     41\u001b[0m         batch_size\u001b[39m=\u001b[39;49mgeneration_batch_size,\n\u001b[1;32m     42\u001b[0m         silent\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m verbose,\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquestion_answerer \u001b[39m=\u001b[39m QuestionAnsweringModel(\n\u001b[1;32m     45\u001b[0m         answering_model_dir,\n\u001b[1;32m     46\u001b[0m         cuda_device\u001b[39m=\u001b[39mcuda_device,\n\u001b[1;32m     47\u001b[0m         batch_size\u001b[39m=\u001b[39manswering_batch_size,\n\u001b[1;32m     48\u001b[0m         silent\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m verbose,\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m verbose\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/qaeval/generation/model.py:31\u001b[0m, in \u001b[0;36mQuestionGenerationModel.__init__\u001b[0;34m(self, model_path, cuda_device, batch_size, silent)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m              model_path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     28\u001b[0m              cuda_device: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m     29\u001b[0m              batch_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m,\n\u001b[1;32m     30\u001b[0m              silent: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor \u001b[39m=\u001b[39m Predictor\u001b[39m.\u001b[39;49mfrom_path(model_path, predictor_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mquestion_generation\u001b[39;49m\u001b[39m'\u001b[39;49m, cuda_device\u001b[39m=\u001b[39;49mcuda_device)\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m silent\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/predictors/predictor.py:277\u001b[0m, in \u001b[0;36mPredictor.from_path\u001b[0;34m(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m import_plugins:\n\u001b[1;32m    275\u001b[0m     plugins\u001b[39m.\u001b[39mimport_plugins()\n\u001b[1;32m    276\u001b[0m \u001b[39mreturn\u001b[39;00m Predictor\u001b[39m.\u001b[39mfrom_archive(\n\u001b[0;32m--> 277\u001b[0m     load_archive(archive_path, cuda_device\u001b[39m=\u001b[39;49mcuda_device),\n\u001b[1;32m    278\u001b[0m     predictor_name,\n\u001b[1;32m    279\u001b[0m     dataset_reader_to_load\u001b[39m=\u001b[39mdataset_reader_to_load,\n\u001b[1;32m    280\u001b[0m     frozen\u001b[39m=\u001b[39mfrozen,\n\u001b[1;32m    281\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/models/archival.py:187\u001b[0m, in \u001b[0;36mload_archive\u001b[0;34m(archive_file, cuda_device, overrides, weights_file)\u001b[0m\n\u001b[1;32m    184\u001b[0m         weights_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(serialization_dir, _DEFAULT_WEIGHTS)\n\u001b[1;32m    186\u001b[0m \u001b[39m# Instantiate model. Use a duplicate of the config, as it will get consumed.\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m model \u001b[39m=\u001b[39m Model\u001b[39m.\u001b[39;49mload(\n\u001b[1;32m    188\u001b[0m     config\u001b[39m.\u001b[39;49mduplicate(),\n\u001b[1;32m    189\u001b[0m     weights_file\u001b[39m=\u001b[39;49mweights_path,\n\u001b[1;32m    190\u001b[0m     serialization_dir\u001b[39m=\u001b[39;49mserialization_dir,\n\u001b[1;32m    191\u001b[0m     cuda_device\u001b[39m=\u001b[39;49mcuda_device,\n\u001b[1;32m    192\u001b[0m )\n\u001b[1;32m    194\u001b[0m \u001b[39mreturn\u001b[39;00m Archive(model\u001b[39m=\u001b[39mmodel, config\u001b[39m=\u001b[39mconfig)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/models/model.py:367\u001b[0m, in \u001b[0;36mModel.load\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(model_class, \u001b[39mtype\u001b[39m):\n\u001b[1;32m    362\u001b[0m     \u001b[39m# If you're using from_archive to specify your model (e.g., for fine tuning), then you\u001b[39;00m\n\u001b[1;32m    363\u001b[0m     \u001b[39m# can't currently override the behavior of _load; we just use the default Model._load.\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39m# If we really need to change this, we would need to implement a recursive\u001b[39;00m\n\u001b[1;32m    365\u001b[0m     \u001b[39m# get_model_class method, that recurses whenever it finds a from_archive model type.\u001b[39;00m\n\u001b[1;32m    366\u001b[0m     model_class \u001b[39m=\u001b[39m Model\n\u001b[0;32m--> 367\u001b[0m \u001b[39mreturn\u001b[39;00m model_class\u001b[39m.\u001b[39;49m_load(config, serialization_dir, weights_file, cuda_device)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/models/model.py:300\u001b[0m, in \u001b[0;36mModel._load\u001b[0;34m(cls, config, serialization_dir, weights_file, cuda_device)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[39m# Force model to cpu or gpu, as appropriate, to make sure that the embeddings are\u001b[39;00m\n\u001b[1;32m    298\u001b[0m \u001b[39m# in sync with the weights\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m cuda_device \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 300\u001b[0m     model\u001b[39m.\u001b[39;49mcuda(cuda_device)\n\u001b[1;32m    301\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     model\u001b[39m.\u001b[39mcpu()\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/nn/modules/module.py:458\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    445\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply(\u001b[39mlambda\u001b[39;49;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/nn/modules/module.py:354\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    353\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 354\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    356\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    358\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    359\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    365\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/nn/modules/module.py:354\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    353\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 354\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    356\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    358\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    359\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    365\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/nn/modules/module.py:354\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_apply\u001b[39m(\u001b[39mself\u001b[39m, fn):\n\u001b[1;32m    353\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren():\n\u001b[0;32m--> 354\u001b[0m         module\u001b[39m.\u001b[39;49m_apply(fn)\n\u001b[1;32m    356\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    357\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    358\u001b[0m             \u001b[39m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    359\u001b[0m             \u001b[39m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[39m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    365\u001b[0m             \u001b[39m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/nn/modules/module.py:376\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[39mif\u001b[39;00m param \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    372\u001b[0m     \u001b[39m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    373\u001b[0m     \u001b[39m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    374\u001b[0m     \u001b[39m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    375\u001b[0m     \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[0;32m--> 376\u001b[0m         param_applied \u001b[39m=\u001b[39m fn(param)\n\u001b[1;32m    377\u001b[0m     should_use_set_data \u001b[39m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    378\u001b[0m     \u001b[39mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/nn/modules/module.py:458\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcuda\u001b[39m(\u001b[39mself\u001b[39m: T, device: Optional[Union[\u001b[39mint\u001b[39m, device]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m T:\n\u001b[1;32m    445\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \n\u001b[1;32m    447\u001b[0m \u001b[39m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m        Module: self\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_apply(\u001b[39mlambda\u001b[39;00m t: t\u001b[39m.\u001b[39;49mcuda(device))\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/cuda/__init__.py:186\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    182\u001b[0m         msg \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mTo use CUDA with multiprocessing, you must use the \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    183\u001b[0m                \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    184\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    185\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m msg)\n\u001b[0;32m--> 186\u001b[0m _check_driver()\n\u001b[1;32m    187\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    188\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[1;32m    189\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/torch/cuda/__init__.py:61\u001b[0m, in \u001b[0;36m_check_driver\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_driver\u001b[39m():\n\u001b[1;32m     60\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_isDriverSufficient\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m---> 61\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_cuda_isDriverSufficient():\n\u001b[1;32m     63\u001b[0m         \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_cuda_getDriverVersion() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     64\u001b[0m             \u001b[39m# found no NVIDIA driver on the system\u001b[39;00m\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "from qafacteval import QAFactEval\n",
    "kwargs = {\"cuda_device\": 0, \"use_lerc_quip\": True, \\\n",
    "        \"verbose\": True, \"generation_batch_size\": 32, \\\n",
    "        \"answering_batch_size\": 32, \"lerc_batch_size\": 8}\n",
    "\n",
    "model_folder = \"\" # path to models downloaded with download_models.sh\n",
    "metric = QAFactEval(\n",
    "    lerc_quip_path=f\"{model_folder}/quip-512-mocha\",\n",
    "    generation_model_path=f\"/Users/mbondarenko/Desktop/long-doc-summ/QAFactEval/models/generation/model.tar.gz\",\n",
    "    answering_model_dir=f\"{model_folder}/answering\",\n",
    "    lerc_model_path=f\"{model_folder}/lerc/model.tar.gz\",\n",
    "    lerc_pretrained_model_path=f\"{model_folder}/lerc/pretraining.tar.gz\",\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "results = metric.score_batch_qafacteval([\"This is a source document\"], [[\"This is a summary.\"]], return_qa_pairs=True)\n",
    "score = results[0][0]['qa-eval']['lerc_quip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
