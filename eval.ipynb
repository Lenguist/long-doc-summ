{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nto implement:\\nR-1, R-2, R-L, BERTScore, METEOR\\nAutomatic metrics to compare against previous papers\\nSNaC for coherence\\nFull code in this repo https://github.com/tagoyal/snac\\nShould be easy to run their T5 models unless I’m retraining\\nQAFactEval for faithfulness\\nFull code in this repo https://github.com/salesforce/QAFactEval#using-qafacteval\\nShould be easy to run but not tested for my domain\\nNeed automatic metric for coverage\\nAI-eval\\nJust ask GPT-4 the same questions as to the humans\\nSee what Faisal is doing with this\\nhttps://arxiv.org/pdf/2305.17926.pdf\\nHuman-eval\\nIs the summary correct relative to the passage?\\nDoes the summary cover the important events?\\nIs the summary well-written and coherent?\\nPreference relative to baseline summary\\nWriting class will evaluate summaries of their own work\\nAdd interpretation here\\nWhat do we want to get out of the eval? Have this drive the approach\\nStrategies from here https://arxiv.org/pdf/2301.13298.pdf\\nError analysis on low quality summaries\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Running different evaluations for long-doc-summ\n",
    "\n",
    "\"\"\"\n",
    "to implement:\n",
    "R-1, R-2, R-L, BERTScore, METEOR\n",
    "Automatic metrics to compare against previous papers\n",
    "SNaC for coherence\n",
    "Full code in this repo https://github.com/tagoyal/snac\n",
    "Should be easy to run their T5 models unless I’m retraining\n",
    "QAFactEval for faithfulness\n",
    "Full code in this repo https://github.com/salesforce/QAFactEval#using-qafacteval\n",
    "Should be easy to run but not tested for my domain\n",
    "Need automatic metric for coverage\n",
    "AI-eval\n",
    "Just ask GPT-4 the same questions as to the humans\n",
    "See what Faisal is doing with this\n",
    "https://arxiv.org/pdf/2305.17926.pdf\n",
    "Human-eval\n",
    "Is the summary correct relative to the passage?\n",
    "Does the summary cover the important events?\n",
    "Is the summary well-written and coherent?\n",
    "Preference relative to baseline summary\n",
    "Writing class will evaluate summaries of their own work\n",
    "Add interpretation here\n",
    "What do we want to get out of the eval? Have this drive the approach\n",
    "Strategies from here https://arxiv.org/pdf/2301.13298.pdf\n",
    "Error analysis on low quality summaries\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_path = \"booksumm-sample2/what-maisie-knew\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(orig_path+\"/metadata.json\") as f:\n",
    "  book_metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'What Maisie Knew',\n",
       " 'author': 'Henry James',\n",
       " 'total-chapters': 31,\n",
       " 'average-chapter-len': 4256.935483870968,\n",
       " 'dir': '7118-chapters'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Maisie has to go back to her father and Miss Overmore . This means that she has to say goodbye to Mrs. Wix for the first time, and this is super, super sad! Maisie asks her father if he liked Miss Overmore \"just the same\" while she was at her mother\\'s . This embarrasses Miss Overmore, even though Beale Farange makes no secret of having been with Miss Overmore the whole time. This is just above Maisie\\'s head. She, too, feels embarrassed and wonders why Miss Overmore has been awkward. She also tries to figure out the nature of her father\\'s relationship to Miss Overmore. Maisie takes to treating her doll, Lisette, the way she herself is treated by her mother and Miss Overmore. She keeps secrets from her doll and even reprimands her for asking indiscreet questions.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Define directory paths\n",
    "dir_path1 = \"booksumm-sample2/what-maisie-knew\"\n",
    "dir_path2 = \"gpt4_summaries/what-maisie-knew\"\n",
    "\n",
    "# Define the data structure\n",
    "data = {\n",
    "    \"subdir\": [],\n",
    "    \"metadata\": [],\n",
    "    \"content\": [],\n",
    "    \"summaries\": [],\n",
    "    \"new_summary\": []\n",
    "}\n",
    "\n",
    "# Loop over subdirectories\n",
    "for subdir in os.listdir(dir_path1):\n",
    "    subdir_path1 = os.path.join(dir_path1, subdir)\n",
    "\n",
    "    # If the path is a directory, process it\n",
    "    if os.path.isdir(subdir_path1):\n",
    "        data[\"subdir\"].append(subdir)\n",
    "\n",
    "        # Process metadata.json\n",
    "        with open(os.path.join(subdir_path1, \"metadata.json\"), 'r') as f:\n",
    "            data[\"metadata\"].append(json.load(f))\n",
    "\n",
    "        # Process content.txt\n",
    "        with open(os.path.join(subdir_path1, \"content.txt\"), 'r') as f:\n",
    "            data[\"content\"].append(f.read())\n",
    "\n",
    "        # Process summaries\n",
    "        summaries = []\n",
    "        for file in os.listdir(subdir_path1):\n",
    "            if file.endswith(\"summary.txt\"):\n",
    "                with open(os.path.join(subdir_path1, file), 'r') as f:\n",
    "                    content = f.read()\n",
    "                    summaries.append(content)\n",
    "        data[\"summaries\"].append(summaries)\n",
    "\n",
    "        # Process new directory\n",
    "        subdir_path2 = os.path.join(dir_path2, subdir)\n",
    "        if os.path.isdir(subdir_path2):\n",
    "            with open(os.path.join(subdir_path2, \"summary.txt\"), 'r') as f:\n",
    "                data[\"new_summary\"].append(f.read())\n",
    "        else:\n",
    "            data[\"new_summary\"].append(None)\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df = df.set_index('subdir')  # Set index to subdirectory names\n",
    "\n",
    "\n",
    "json.loads(df['summaries'][0][0])[\"summary\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>content</th>\n",
       "      <th>summaries</th>\n",
       "      <th>new_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdir</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '05...</td>\n",
       "      <td>\\n\\nThe second parting from Miss Overmore had ...</td>\n",
       "      <td>[{\"name\": \"Chapter V\", \"url\": \"https://web.arc...</td>\n",
       "      <td>This chapter revolves around a young girl name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '21...</td>\n",
       "      <td>\\n\\nA good deal of the rest of Ida's visit was...</td>\n",
       "      <td>[{\"name\": \"Chapter XXI\", \"url\": \"https://web.a...</td>\n",
       "      <td>In this chapter, Maisie and her mother, Ida, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '30...</td>\n",
       "      <td>\\n\\nAfter they were seated there it was differ...</td>\n",
       "      <td>[{\"name\": \"Chapter XXX\", \"url\": \"https://web.a...</td>\n",
       "      <td>In this chapter, Sir Claude and Maisie have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '23...</td>\n",
       "      <td>\\n\\nSir Claude was stationed at the window; he...</td>\n",
       "      <td>[{\"name\": \"Chapter XXIII\", \"url\": \"https://web...</td>\n",
       "      <td>In this chapter, Mrs. Wix, Sir Claude, and Mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '14...</td>\n",
       "      <td>\\n\\nMrs Beale fairly swooped upon her and the ...</td>\n",
       "      <td>[{\"name\": \"Chapter XIV\", \"url\": \"https://web.a...</td>\n",
       "      <td>In this chapter, Maisie is reunited with her s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 metadata  \\\n",
       "subdir                                                      \n",
       "05      {'book-id': '7118-chapters', 'chapter-id': '05...   \n",
       "21      {'book-id': '7118-chapters', 'chapter-id': '21...   \n",
       "30      {'book-id': '7118-chapters', 'chapter-id': '30...   \n",
       "23      {'book-id': '7118-chapters', 'chapter-id': '23...   \n",
       "14      {'book-id': '7118-chapters', 'chapter-id': '14...   \n",
       "\n",
       "                                                  content  \\\n",
       "subdir                                                      \n",
       "05      \\n\\nThe second parting from Miss Overmore had ...   \n",
       "21      \\n\\nA good deal of the rest of Ida's visit was...   \n",
       "30      \\n\\nAfter they were seated there it was differ...   \n",
       "23      \\n\\nSir Claude was stationed at the window; he...   \n",
       "14      \\n\\nMrs Beale fairly swooped upon her and the ...   \n",
       "\n",
       "                                                summaries  \\\n",
       "subdir                                                      \n",
       "05      [{\"name\": \"Chapter V\", \"url\": \"https://web.arc...   \n",
       "21      [{\"name\": \"Chapter XXI\", \"url\": \"https://web.a...   \n",
       "30      [{\"name\": \"Chapter XXX\", \"url\": \"https://web.a...   \n",
       "23      [{\"name\": \"Chapter XXIII\", \"url\": \"https://web...   \n",
       "14      [{\"name\": \"Chapter XIV\", \"url\": \"https://web.a...   \n",
       "\n",
       "                                              new_summary  \n",
       "subdir                                                     \n",
       "05      This chapter revolves around a young girl name...  \n",
       "21      In this chapter, Maisie and her mother, Ida, s...  \n",
       "30      In this chapter, Sir Claude and Maisie have a ...  \n",
       "23      In this chapter, Mrs. Wix, Sir Claude, and Mai...  \n",
       "14      In this chapter, Maisie is reunited with her s...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_summary(summary_list):\n",
    "  new_list = []\n",
    "  for summary in summary_list:\n",
    "    out = json.loads(summary)[\"summary\"]\n",
    "    new_list.append(out)\n",
    "  return new_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"summaries\"] = df['summaries'].apply(process_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>metadata</th>\n",
       "      <th>content</th>\n",
       "      <th>summaries</th>\n",
       "      <th>new_summary</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subdir</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>05</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '05...</td>\n",
       "      <td>\\n\\nThe second parting from Miss Overmore had ...</td>\n",
       "      <td>[Maisie has to go back to her father and Miss ...</td>\n",
       "      <td>This chapter revolves around a young girl name...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '21...</td>\n",
       "      <td>\\n\\nA good deal of the rest of Ida's visit was...</td>\n",
       "      <td>[Ida and Maisie have a heart-to-heart. Ida is ...</td>\n",
       "      <td>In this chapter, Maisie and her mother, Ida, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '30...</td>\n",
       "      <td>\\n\\nAfter they were seated there it was differ...</td>\n",
       "      <td>[Maisie's cafe trip with Sir Claude turns into...</td>\n",
       "      <td>In this chapter, Sir Claude and Maisie have a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '23...</td>\n",
       "      <td>\\n\\nSir Claude was stationed at the window; he...</td>\n",
       "      <td>[Mrs. Wix says that she has seen Maisie's moth...</td>\n",
       "      <td>In this chapter, Mrs. Wix, Sir Claude, and Mai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'book-id': '7118-chapters', 'chapter-id': '14...</td>\n",
       "      <td>\\n\\nMrs Beale fairly swooped upon her and the ...</td>\n",
       "      <td>[Mrs. Beale lets it slip that she and Sir Clau...</td>\n",
       "      <td>In this chapter, Maisie is reunited with her s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 metadata  \\\n",
       "subdir                                                      \n",
       "05      {'book-id': '7118-chapters', 'chapter-id': '05...   \n",
       "21      {'book-id': '7118-chapters', 'chapter-id': '21...   \n",
       "30      {'book-id': '7118-chapters', 'chapter-id': '30...   \n",
       "23      {'book-id': '7118-chapters', 'chapter-id': '23...   \n",
       "14      {'book-id': '7118-chapters', 'chapter-id': '14...   \n",
       "\n",
       "                                                  content  \\\n",
       "subdir                                                      \n",
       "05      \\n\\nThe second parting from Miss Overmore had ...   \n",
       "21      \\n\\nA good deal of the rest of Ida's visit was...   \n",
       "30      \\n\\nAfter they were seated there it was differ...   \n",
       "23      \\n\\nSir Claude was stationed at the window; he...   \n",
       "14      \\n\\nMrs Beale fairly swooped upon her and the ...   \n",
       "\n",
       "                                                summaries  \\\n",
       "subdir                                                      \n",
       "05      [Maisie has to go back to her father and Miss ...   \n",
       "21      [Ida and Maisie have a heart-to-heart. Ida is ...   \n",
       "30      [Maisie's cafe trip with Sir Claude turns into...   \n",
       "23      [Mrs. Wix says that she has seen Maisie's moth...   \n",
       "14      [Mrs. Beale lets it slip that she and Sir Clau...   \n",
       "\n",
       "                                              new_summary  \n",
       "subdir                                                     \n",
       "05      This chapter revolves around a young girl name...  \n",
       "21      In this chapter, Maisie and her mother, Ida, s...  \n",
       "30      In this chapter, Sir Claude and Maisie have a ...  \n",
       "23      In this chapter, Mrs. Wix, Sir Claude, and Mai...  \n",
       "14      In this chapter, Maisie is reunited with her s...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: absl-py in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (1.4.0)\n",
      "Requirement already satisfied: nltk in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (1.24.4)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: click in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk->rouge_score) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: nltk in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: tqdm in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from nltk) (4.65.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge_score\n",
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/mbondarenko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/mbondarenko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/mbondarenko/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "meteor = evaluate.load(\"meteor\")\n",
    "rouge = evaluate.load('rouge')\n",
    "bertscore = evaluate.load(\"bertscore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:absl:Using default tokenizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rouge1': 0.41354723707664887, 'rouge2': 0.11091234347048301, 'rougeL': 0.19576719576719573, 'rougeLsum': 0.25396825396825395}\n",
      "{'meteor': 0.35806239548866164}\n",
      "{'precision': [0.7972561120986938], 'recall': [0.8193682432174683], 'f1': [0.7973999381065369], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=3.0.2)'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = [df[\"new_summary\"][0]]\n",
    "references = [df[\"summaries\"][0]]\n",
    "print(rouge.compute(predictions=predictions,references=references))\n",
    "print(meteor.compute(predictions=predictions,references=references))\n",
    "print(bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': [0.7972561120986938], 'recall': [0.8193682432174683], 'f1': [0.7973999381065369], 'hashcode': 'distilbert-base-uncased_L5_no-idf_version=0.3.12(hug_trans=3.0.2)'}\n"
     ]
    }
   ],
   "source": [
    "from evaluate import load\n",
    "bertscore = load(\"bertscore\")\n",
    "results = bertscore.compute(predictions=predictions, references=references, model_type=\"distilbert-base-uncased\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "DEPRECATION: https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz#egg=en_core_web_sm==2.2.5 contains an egg fragment with a non-PEP 508 name pip 25.0 will enforce this behaviour change. A possible replacement is to use the req @ url syntax, and remove the egg fragment. Discussion can be found at https://github.com/pypa/pip/issues/11617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en_core_web_sm==2.2.5\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n",
      "\u001b[2K     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.0/12.0 MB 10.5 MB/s eta 0:00:00\n",
      "\u001b[?25h  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy>=2.2.2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from en_core_web_sm==2.2.5) (2.2.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.9)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.7)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.8)\n",
      "Requirement already satisfied: thinc==7.4.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.10.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.65.0)\n",
      "Requirement already satisfied: setuptools in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (67.8.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/mbondarenko/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2023.5.7)\n",
      "Building wheels for collected packages: en_core_web_sm\n",
      "  Building wheel for en_core_web_sm (setup.py): started\n",
      "  Building wheel for en_core_web_sm (setup.py): finished with status 'done'\n",
      "  Created wheel for en_core_web_sm: filename=en_core_web_sm-2.2.5-py3-none-any.whl size=12011718 sha256=af59cf5c7a9daec2965fbfa5b48d346edccf4a9c5c2d1c85e06e649d21f74a5b\n",
      "  Stored in directory: /private/var/folders/km/4_y5sdb51yg4g56t_jx0nt740000gn/T/pip-ephem-wheel-cache-r0a8h11r/wheels/77/b4/c8/395804b9a2b6864aaff3623d7b709680acc3d04f47c8162ee6\n",
      "Successfully built en_core_web_sm\n",
      "Installing collected packages: en_core_web_sm\n",
      "Successfully installed en_core_web_sm-2.2.5\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "file /generation/model.tar.gz not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m kwargs \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39mcuda_device\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39muse_lerc_quip\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \\\n\u001b[1;32m      3\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mverbose\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39mgeneration_batch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m32\u001b[39m, \\\n\u001b[1;32m      4\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39manswering_batch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m32\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mlerc_batch_size\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m8\u001b[39m}\n\u001b[1;32m      6\u001b[0m model_folder \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m# path to models downloaded with download_models.sh\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m metric \u001b[39m=\u001b[39m QAFactEval(\n\u001b[1;32m      8\u001b[0m     lerc_quip_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/quip-512-mocha\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m     generation_model_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/generation/model.tar.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     10\u001b[0m     answering_model_dir\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/answering\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     11\u001b[0m     lerc_model_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/lerc/model.tar.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     12\u001b[0m     lerc_pretrained_model_path\u001b[39m=\u001b[39;49m\u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m{\u001b[39;49;00mmodel_folder\u001b[39m}\u001b[39;49;00m\u001b[39m/lerc/pretraining.tar.gz\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m     14\u001b[0m )\n\u001b[1;32m     16\u001b[0m results \u001b[39m=\u001b[39m metric\u001b[39m.\u001b[39mscore_batch_qafacteval([\u001b[39m\"\u001b[39m\u001b[39mThis is a source document\u001b[39m\u001b[39m\"\u001b[39m], [[\u001b[39m\"\u001b[39m\u001b[39mThis is a summary.\u001b[39m\u001b[39m\"\u001b[39m]], return_qa_pairs\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m     17\u001b[0m score \u001b[39m=\u001b[39m results[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mqa-eval\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mlerc_quip\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/Desktop/long-doc-summ/QAFactEval/qafacteval.py:46\u001b[0m, in \u001b[0;36mQAFactEval.__init__\u001b[0;34m(self, lerc_quip_path, use_lerc_quip, lerc_batch_size, cuda_device, *args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcli\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     spacy\u001b[39m.\u001b[39mcli\u001b[39m.\u001b[39mdownload(\u001b[39m\"\u001b[39m\u001b[39men_core_web_sm\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(cuda_device\u001b[39m=\u001b[39;49mcuda_device, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     48\u001b[0m \u001b[39mif\u001b[39;00m use_lerc_quip:\n\u001b[1;32m     49\u001b[0m     lerc_quip \u001b[39m=\u001b[39m LERCQuipScorer(lerc_quip_path\u001b[39m=\u001b[39mlerc_quip_path, \\\n\u001b[1;32m     50\u001b[0m         cuda_device\u001b[39m=\u001b[39mcuda_device, batch_size\u001b[39m=\u001b[39mlerc_batch_size)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/qaeval/metric.py:38\u001b[0m, in \u001b[0;36mQAEval.__init__\u001b[0;34m(self, generation_model_path, answering_model_dir, answer_selection_strategy, cuda_device, generation_batch_size, answering_batch_size, use_lerc, lerc_model_path, lerc_pretrained_model_path, lerc_batch_size, verbose)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\n\u001b[1;32m     24\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     25\u001b[0m     generation_model_path: \u001b[39mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     verbose: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39manswer_selector \u001b[39m=\u001b[39m AnswerSelector(answer_selection_strategy)\n\u001b[0;32m---> 38\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquestion_generator \u001b[39m=\u001b[39m QuestionGenerationModel(\n\u001b[1;32m     39\u001b[0m         generation_model_path,\n\u001b[1;32m     40\u001b[0m         cuda_device\u001b[39m=\u001b[39;49mcuda_device,\n\u001b[1;32m     41\u001b[0m         batch_size\u001b[39m=\u001b[39;49mgeneration_batch_size,\n\u001b[1;32m     42\u001b[0m         silent\u001b[39m=\u001b[39;49m\u001b[39mnot\u001b[39;49;00m verbose,\n\u001b[1;32m     43\u001b[0m     )\n\u001b[1;32m     44\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquestion_answerer \u001b[39m=\u001b[39m QuestionAnsweringModel(\n\u001b[1;32m     45\u001b[0m         answering_model_dir,\n\u001b[1;32m     46\u001b[0m         cuda_device\u001b[39m=\u001b[39mcuda_device,\n\u001b[1;32m     47\u001b[0m         batch_size\u001b[39m=\u001b[39manswering_batch_size,\n\u001b[1;32m     48\u001b[0m         silent\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m verbose,\n\u001b[1;32m     49\u001b[0m     )\n\u001b[1;32m     50\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m=\u001b[39m verbose\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/qaeval/generation/model.py:31\u001b[0m, in \u001b[0;36mQuestionGenerationModel.__init__\u001b[0;34m(self, model_path, cuda_device, batch_size, silent)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[1;32m     27\u001b[0m              model_path: \u001b[39mstr\u001b[39m,\n\u001b[1;32m     28\u001b[0m              cuda_device: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m,\n\u001b[1;32m     29\u001b[0m              batch_size: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m,\n\u001b[1;32m     30\u001b[0m              silent: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 31\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredictor \u001b[39m=\u001b[39m Predictor\u001b[39m.\u001b[39;49mfrom_path(model_path, predictor_name\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mquestion_generation\u001b[39;49m\u001b[39m'\u001b[39;49m, cuda_device\u001b[39m=\u001b[39;49mcuda_device)\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size \u001b[39m=\u001b[39m batch_size\n\u001b[1;32m     33\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msilent \u001b[39m=\u001b[39m silent\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/predictors/predictor.py:277\u001b[0m, in \u001b[0;36mPredictor.from_path\u001b[0;34m(cls, archive_path, predictor_name, cuda_device, dataset_reader_to_load, frozen, import_plugins)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[39mif\u001b[39;00m import_plugins:\n\u001b[1;32m    275\u001b[0m     plugins\u001b[39m.\u001b[39mimport_plugins()\n\u001b[1;32m    276\u001b[0m \u001b[39mreturn\u001b[39;00m Predictor\u001b[39m.\u001b[39mfrom_archive(\n\u001b[0;32m--> 277\u001b[0m     load_archive(archive_path, cuda_device\u001b[39m=\u001b[39;49mcuda_device),\n\u001b[1;32m    278\u001b[0m     predictor_name,\n\u001b[1;32m    279\u001b[0m     dataset_reader_to_load\u001b[39m=\u001b[39mdataset_reader_to_load,\n\u001b[1;32m    280\u001b[0m     frozen\u001b[39m=\u001b[39mfrozen,\n\u001b[1;32m    281\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/models/archival.py:154\u001b[0m, in \u001b[0;36mload_archive\u001b[0;34m(archive_file, cuda_device, overrides, weights_file)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[39mInstantiates an Archive from an archived `tar.gz` file.\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39m    The weights file to use.  If unspecified, weights.th in the archive_file will be used.\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \u001b[39m# redirect to the cache, if necessary\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m resolved_archive_file \u001b[39m=\u001b[39m cached_path(archive_file)\n\u001b[1;32m    156\u001b[0m \u001b[39mif\u001b[39;00m resolved_archive_file \u001b[39m==\u001b[39m archive_file:\n\u001b[1;32m    157\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloading archive file \u001b[39m\u001b[39m{\u001b[39;00marchive_file\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/long-doc-summ/lib/python3.8/site-packages/allennlp/common/file_utils.py:175\u001b[0m, in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, extract_archive, force_extract)\u001b[0m\n\u001b[1;32m    171\u001b[0m         extraction_path \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(extraction_dir, extraction_name)\n\u001b[1;32m    173\u001b[0m \u001b[39melif\u001b[39;00m parsed\u001b[39m.\u001b[39mscheme \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    174\u001b[0m     \u001b[39m# File, but it doesn't exist.\u001b[39;00m\n\u001b[0;32m--> 175\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mFileNotFoundError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile \u001b[39m\u001b[39m{\u001b[39;00murl_or_filename\u001b[39m}\u001b[39;00m\u001b[39m not found\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     \u001b[39m# Something unknown\u001b[39;00m\n\u001b[1;32m    179\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39munable to parse \u001b[39m\u001b[39m{\u001b[39;00murl_or_filename\u001b[39m}\u001b[39;00m\u001b[39m as a URL or as a local path\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: file /generation/model.tar.gz not found"
     ]
    }
   ],
   "source": [
    "from qafacteval import QAFactEval\n",
    "kwargs = {\"cuda_device\": 0, \"use_lerc_quip\": True, \\\n",
    "        \"verbose\": True, \"generation_batch_size\": 32, \\\n",
    "        \"answering_batch_size\": 32, \"lerc_batch_size\": 8}\n",
    "\n",
    "model_folder = \"\" # path to models downloaded with download_models.sh\n",
    "metric = QAFactEval(\n",
    "    lerc_quip_path=f\"{model_folder}/quip-512-mocha\",\n",
    "    generation_model_path=f\"{model_folder}/generation/model.tar.gz\",\n",
    "    answering_model_dir=f\"{model_folder}/answering\",\n",
    "    lerc_model_path=f\"{model_folder}/lerc/model.tar.gz\",\n",
    "    lerc_pretrained_model_path=f\"{model_folder}/lerc/pretraining.tar.gz\",\n",
    "    **kwargs\n",
    ")\n",
    "\n",
    "results = metric.score_batch_qafacteval([\"This is a source document\"], [[\"This is a summary.\"]], return_qa_pairs=True)\n",
    "score = results[0][0]['qa-eval']['lerc_quip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
