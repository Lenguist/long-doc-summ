{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take untokenized data\n",
    "# compile it into one table\n",
    "# get avarage length of recap, average length of dialogue, for each subset of data ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install transformers library to get GPT2 tokenizer\n",
    "%pip install transformers --quiet\n",
    "\n",
    "# initializing gpt2 tokenizer\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# define the directory\n",
    "dir_path = 'SummScreen_raw/fd'\n",
    "\n",
    "# initialize an empty list to store each json data\n",
    "fd_data = []\n",
    "\n",
    "# iterate over each file in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.json'):  # make sure to only deal with .json files\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)  # load json data from file\n",
    "            # create a new field 'transcript_joined' which is the transcript list joined into one string\n",
    "            data['transcript_joined'] = ' '.join(data['Transcript'])\n",
    "            data['Recap'] = ' '.join(data['Recap'])\n",
    "            # create a new field 'transcript_length' which is the length of the 'transcript_joined' string\n",
    "            # replace it with tokenizer later\n",
    "            #data['transcript_length'] = len(tokenizer(data['transcript_joined'])['input_ids'])\n",
    "            #data['recap_length'] = len(tokenizer(data['transcript_joined'])['input_ids'])\n",
    "            data['approx_transcript_length'] = len(data['transcript_joined'].split(\" \"))\n",
    "            data['approx_recap_length'] = len(data['Recap'].split(\" \"))\n",
    "            fd_data.append(data)  # add this data dict to the list\n",
    "\n",
    "# now data_list is a list of dicts, can be directly used to create dataframe\n",
    "fd_df = pd.DataFrame(fd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the directory\n",
    "dir_path = 'SummScreen_raw/tms'\n",
    "\n",
    "# initialize an empty list to store each json data\n",
    "tms_data = []\n",
    "\n",
    "# iterate over each file in the directory\n",
    "for filename in os.listdir(dir_path):\n",
    "    if filename.endswith('.json'):  # make sure to only deal with .json files\n",
    "        file_path = os.path.join(dir_path, filename)\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)  # load json data from file\n",
    "            # create a new field 'transcript_joined' which is the transcript list joined into one string\n",
    "            data['transcript_joined'] = ' '.join(data['Transcript'])\n",
    "            data['Recap'] = ' '.join(data['Recap'])\n",
    "            # create a new field 'transcript_length' which is the length of the 'transcript_joined' string\n",
    "            # replace it with tokenizer later\n",
    "            #data['transcript_length'] = len(tokenizer(data['transcript_joined'])['input_ids'])\n",
    "            #data['recap_length'] = len(tokenizer(data['transcript_joined'])['input_ids'])\n",
    "            data['approx_transcript_length'] = len(data['transcript_joined'].split(\" \"))\n",
    "            data['approx_recap_length'] = len(data['Recap'].split(\" \"))\n",
    "            tms_data.append(data)  # add this data dict to the list\n",
    "\n",
    "# now data_list is a list of dicts, can be directly used to create dataframe\n",
    "tms_df = pd.DataFrame(tms_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Episode Summary</th>\n",
       "      <th>Recap</th>\n",
       "      <th>Recap Author</th>\n",
       "      <th>Show Title</th>\n",
       "      <th>Transcript</th>\n",
       "      <th>Transcript Author</th>\n",
       "      <th>transcript_joined</th>\n",
       "      <th>approx_transcript_length</th>\n",
       "      <th>approx_recap_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>The Great Victor Newman has returned to Genoa ...</td>\n",
       "      <td>Asiya</td>\n",
       "      <td>Young and the Restless</td>\n",
       "      <td>[[Victoria daydreaming], Victoria: (Sighs) Dad...</td>\n",
       "      <td>[Provided By Eric Proofread By Emma]</td>\n",
       "      <td>[Victoria daydreaming] Victoria: (Sighs) Daddy...</td>\n",
       "      <td>4951</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>When Nikolas begins to die on the table, Emily...</td>\n",
       "      <td>Amanda</td>\n",
       "      <td>General Hospital</td>\n",
       "      <td>[Peg: There comes a time when you realize that...</td>\n",
       "      <td>[Provided By Boo Proofread By Kathy]</td>\n",
       "      <td>Peg: There comes a time when you realize that ...</td>\n",
       "      <td>5689</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[]</td>\n",
       "      <td>Jennifer was on the phone with a reporter talk...</td>\n",
       "      <td>Michele and Cheryl</td>\n",
       "      <td>Days of Our Lives</td>\n",
       "      <td>[Jennifer: Listen, as I have already told you,...</td>\n",
       "      <td>[Provided By Suzanne Proofread By Gisele]</td>\n",
       "      <td>Jennifer: Listen, as I have already told you, ...</td>\n",
       "      <td>5143</td>\n",
       "      <td>811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>Taylor continues her melt down crying over Rid...</td>\n",
       "      <td>Beth</td>\n",
       "      <td>Bold and the Beautiful</td>\n",
       "      <td>[Taylor: You saved me from a marriage that was...</td>\n",
       "      <td>[Provided By Boo Proofread by Becky]</td>\n",
       "      <td>Taylor: You saved me from a marriage that wasn...</td>\n",
       "      <td>1718</td>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[]</td>\n",
       "      <td>Rick shows up at work feeling pretty low and a...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Bold and the Beautiful</td>\n",
       "      <td>[Brooke: Yeah, sure, Katie. I'll come take a l...</td>\n",
       "      <td>[Provided By Suzanne Proofread by Becky]</td>\n",
       "      <td>Brooke: Yeah, sure, Katie. I'll come take a lo...</td>\n",
       "      <td>2873</td>\n",
       "      <td>290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23669</th>\n",
       "      <td>[]</td>\n",
       "      <td>Erica is in major denial, burying herself in c...</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>All My Children</td>\n",
       "      <td>[Tad: What the hell is wrong with this girl? W...</td>\n",
       "      <td>[Provided by Suzanne Proofread by Gisele]</td>\n",
       "      <td>Tad: What the hell is wrong with this girl? Wh...</td>\n",
       "      <td>6014</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23670</th>\n",
       "      <td>[]</td>\n",
       "      <td>Brooke needs no explanation, she sees what is ...</td>\n",
       "      <td>Wanda</td>\n",
       "      <td>Bold and the Beautiful</td>\n",
       "      <td>[Brooke: Oh, my God. After everything -- what ...</td>\n",
       "      <td>[Provided By Boo Proofread by Becky]</td>\n",
       "      <td>Brooke: Oh, my God. After everything -- what a...</td>\n",
       "      <td>2733</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23671</th>\n",
       "      <td>[Episode # 10438 ~ Nick's reluctance to trust ...</td>\n",
       "      <td>Neil and Hilary decide to get married tomorrow...</td>\n",
       "      <td>Eva</td>\n",
       "      <td>Young and the Restless</td>\n",
       "      <td>[Mark: I did what you asked -- followed Willa ...</td>\n",
       "      <td>[Provided By Suzanne]</td>\n",
       "      <td>Mark: I did what you asked -- followed Willa a...</td>\n",
       "      <td>5800</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23672</th>\n",
       "      <td>[Episode # 10024 ~ Nick Could Expose Sharon's ...</td>\n",
       "      <td>At the Athletic Club, Phyllis moves in a littl...</td>\n",
       "      <td>Mary</td>\n",
       "      <td>Young and the Restless</td>\n",
       "      <td>[(Key turns in lock), Jack: Uh, scotch, neat.,...</td>\n",
       "      <td>[Provided By Suzanne Proofread By Emma]</td>\n",
       "      <td>(Key turns in lock) Jack: Uh, scotch, neat. Ph...</td>\n",
       "      <td>4628</td>\n",
       "      <td>596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23673</th>\n",
       "      <td>[]</td>\n",
       "      <td>John, Jack, Lucas, Bo, and Tony all end up at ...</td>\n",
       "      <td>Rebecca</td>\n",
       "      <td>Days of Our Lives</td>\n",
       "      <td>[Belle: Oh, hey, no. That's mine. It stays., C...</td>\n",
       "      <td>[By Eric]</td>\n",
       "      <td>Belle: Oh, hey, no. That's mine. It stays. Cas...</td>\n",
       "      <td>5161</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23674 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Episode Summary  \\\n",
       "0                                                     []   \n",
       "1                                                     []   \n",
       "2                                                     []   \n",
       "3                                                     []   \n",
       "4                                                     []   \n",
       "...                                                  ...   \n",
       "23669                                                 []   \n",
       "23670                                                 []   \n",
       "23671  [Episode # 10438 ~ Nick's reluctance to trust ...   \n",
       "23672  [Episode # 10024 ~ Nick Could Expose Sharon's ...   \n",
       "23673                                                 []   \n",
       "\n",
       "                                                   Recap        Recap Author  \\\n",
       "0      The Great Victor Newman has returned to Genoa ...               Asiya   \n",
       "1      When Nikolas begins to die on the table, Emily...              Amanda   \n",
       "2      Jennifer was on the phone with a reporter talk...  Michele and Cheryl   \n",
       "3      Taylor continues her melt down crying over Rid...                Beth   \n",
       "4      Rick shows up at work feeling pretty low and a...               Wanda   \n",
       "...                                                  ...                 ...   \n",
       "23669  Erica is in major denial, burying herself in c...            Jennifer   \n",
       "23670  Brooke needs no explanation, she sees what is ...               Wanda   \n",
       "23671  Neil and Hilary decide to get married tomorrow...                 Eva   \n",
       "23672  At the Athletic Club, Phyllis moves in a littl...                Mary   \n",
       "23673  John, Jack, Lucas, Bo, and Tony all end up at ...             Rebecca   \n",
       "\n",
       "                   Show Title  \\\n",
       "0      Young and the Restless   \n",
       "1            General Hospital   \n",
       "2           Days of Our Lives   \n",
       "3      Bold and the Beautiful   \n",
       "4      Bold and the Beautiful   \n",
       "...                       ...   \n",
       "23669         All My Children   \n",
       "23670  Bold and the Beautiful   \n",
       "23671  Young and the Restless   \n",
       "23672  Young and the Restless   \n",
       "23673       Days of Our Lives   \n",
       "\n",
       "                                              Transcript  \\\n",
       "0      [[Victoria daydreaming], Victoria: (Sighs) Dad...   \n",
       "1      [Peg: There comes a time when you realize that...   \n",
       "2      [Jennifer: Listen, as I have already told you,...   \n",
       "3      [Taylor: You saved me from a marriage that was...   \n",
       "4      [Brooke: Yeah, sure, Katie. I'll come take a l...   \n",
       "...                                                  ...   \n",
       "23669  [Tad: What the hell is wrong with this girl? W...   \n",
       "23670  [Brooke: Oh, my God. After everything -- what ...   \n",
       "23671  [Mark: I did what you asked -- followed Willa ...   \n",
       "23672  [(Key turns in lock), Jack: Uh, scotch, neat.,...   \n",
       "23673  [Belle: Oh, hey, no. That's mine. It stays., C...   \n",
       "\n",
       "                               Transcript Author  \\\n",
       "0           [Provided By Eric Proofread By Emma]   \n",
       "1           [Provided By Boo Proofread By Kathy]   \n",
       "2      [Provided By Suzanne Proofread By Gisele]   \n",
       "3           [Provided By Boo Proofread by Becky]   \n",
       "4       [Provided By Suzanne Proofread by Becky]   \n",
       "...                                          ...   \n",
       "23669  [Provided by Suzanne Proofread by Gisele]   \n",
       "23670       [Provided By Boo Proofread by Becky]   \n",
       "23671                      [Provided By Suzanne]   \n",
       "23672    [Provided By Suzanne Proofread By Emma]   \n",
       "23673                                  [By Eric]   \n",
       "\n",
       "                                       transcript_joined  \\\n",
       "0      [Victoria daydreaming] Victoria: (Sighs) Daddy...   \n",
       "1      Peg: There comes a time when you realize that ...   \n",
       "2      Jennifer: Listen, as I have already told you, ...   \n",
       "3      Taylor: You saved me from a marriage that wasn...   \n",
       "4      Brooke: Yeah, sure, Katie. I'll come take a lo...   \n",
       "...                                                  ...   \n",
       "23669  Tad: What the hell is wrong with this girl? Wh...   \n",
       "23670  Brooke: Oh, my God. After everything -- what a...   \n",
       "23671  Mark: I did what you asked -- followed Willa a...   \n",
       "23672  (Key turns in lock) Jack: Uh, scotch, neat. Ph...   \n",
       "23673  Belle: Oh, hey, no. That's mine. It stays. Cas...   \n",
       "\n",
       "       approx_transcript_length  approx_recap_length  \n",
       "0                          4951                  196  \n",
       "1                          5689                  150  \n",
       "2                          5143                  811  \n",
       "3                          1718                  101  \n",
       "4                          2873                  290  \n",
       "...                         ...                  ...  \n",
       "23669                      6014                  158  \n",
       "23670                      2733                  277  \n",
       "23671                      5800                  286  \n",
       "23672                      4628                  596  \n",
       "23673                      5161                   80  \n",
       "\n",
       "[23674 rows x 9 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tms_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample 20 shows from the final dataframe\n",
    "sampled_shows = final_df['Show Title'].drop_duplicates().sample(20)\n",
    "\n",
    "# Get all rows from these sampled shows\n",
    "final_sampled_df = final_df[final_df['Show Title'].isin(sampled_shows)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23674"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4398"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "\n",
    "# Group by show and calculate the mean transcript length for each show\n",
    "grouped_means = tms_df.groupby('Show Title')['approx_transcript_length'].mean()\n",
    "\n",
    "# Filter shows with mean transcript length between 3000 and 7300\n",
    "valid_shows = grouped_means[(grouped_means > 3000) & (grouped_means < 7300)].index\n",
    "\n",
    "# Filter original dataframe to only include rows from valid shows\n",
    "filtered_df = tms_df[tms_df['Show Title'].isin(valid_shows)]\n",
    "\n",
    "# Further filter to only include shows with at least 5 transcripts\n",
    "final_df = filtered_df.groupby('Show Title').filter(lambda x: len(x) >= 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "\n",
    "# Group by show and calculate the mean transcript length for each show\n",
    "grouped_means = fd_df.groupby('Show Title')['approx_transcript_length'].mean()\n",
    "\n",
    "# Filter shows with mean transcript length between 3000 and 7300\n",
    "valid_shows = grouped_means[(grouped_means > 3000) & (grouped_means < 7300)].index\n",
    "\n",
    "# Filter original dataframe to only include rows from valid shows\n",
    "filtered_df = fd_df[fd_df['Show Title'].isin(valid_shows)]\n",
    "\n",
    "# Further filter to only include shows with at least 5 transcripts\n",
    "final_df = filtered_df.groupby('Show Title').filter(lambda x: len(x) >= 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4398"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fd_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23674"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tms_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show Title\n",
      "Alias                     6278.847619\n",
      "All American              6826.000000\n",
      "Almost Royal              3368.666667\n",
      "American Horror Story     6520.500000\n",
      "Angel                     7142.569231\n",
      "                             ...     \n",
      "Veronica Mars            10263.250000\n",
      "Vikings                   2498.000000\n",
      "We Bare Bears             3334.000000\n",
      "Westworld                 4690.000000\n",
      "You re the Worst          3138.000000\n",
      "Name: approx_transcript_length, Length: 92, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(grouped_means)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your dataframe\n",
    "\n",
    "# Group by show and calculate the mean transcript length for each show\n",
    "grouped_means = tms_df.groupby('Show Title')['approx_transcript_length'].mean()\n",
    "\n",
    "# Filter shows with mean transcript length between 3000 and 7300\n",
    "valid_shows = grouped_means[(grouped_means > 3000) & (grouped_means < 7300)].index\n",
    "\n",
    "# Filter original dataframe to only include rows from valid shows\n",
    "filtered_df = tms_df[tms_df['Show Title'].isin(valid_shows)]\n",
    "\n",
    "# Further filter to only include shows with at least 5 transcripts\n",
    "final_df = filtered_df.groupby('Show Title').filter(lambda x: len(x) >= 5)\n",
    "\n",
    "# Count the number of unique shows in the final dataframe\n",
    "num_unique_shows = final_df['Show Title'].nunique()\n",
    "\n",
    "# Sample the smaller of num_unique_shows and 20\n",
    "sample_size = min(num_unique_shows, 20)\n",
    "sampled_shows = final_df['Show Title'].drop_duplicates().sample(sample_size)\n",
    "\n",
    "# Get all rows from these sampled shows\n",
    "final_sampled_df = final_df[final_df['Show Title'].isin(sampled_shows)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample 100 form TVMegaSite\n",
    "#>3k <7.3k\n",
    "#5 from the same show, 20 shows sampled randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 100 from both forever dreaming and tms,\n",
    "# then ran snac on them to see which reference summaries have higher coherence quality \n",
    "# decide from there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average transcript length:  4761.670017740982\n",
      "Average recap length:  337.8455267381938\n"
     ]
    }
   ],
   "source": [
    "#TVMegaSite\n",
    "average_transcript_length = tms_df['approx_transcript_length'].mean()\n",
    "average_recap_length = tms_df['approx_recap_length'].mean()\n",
    "\n",
    "print(\"Average transcript length: \", average_transcript_length)\n",
    "print(\"Average recap length: \", average_recap_length)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average transcript length:  5623.9763528876765\n",
      "Average recap length:  99.12551159618008\n"
     ]
    }
   ],
   "source": [
    "average_transcript_length = fd_df['approx_transcript_length'].mean()\n",
    "average_recap_length = fd_df['approx_recap_length'].mean()\n",
    "\n",
    "print(\"Average transcript length: \", average_transcript_length)\n",
    "print(\"Average recap length: \", average_recap_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a random row from the DataFrame\n",
    "sample_row = fd_df.sample(1)\n",
    "\n",
    "# Get the recap and transcript from the sampled row\n",
    "sample_recap = sample_row['Recap'].values[0]\n",
    "sample_transcript = sample_row['transcript_joined'].values[0]\n",
    "\n",
    "# Write the recap and transcript to separate text files\n",
    "with open('sample_recap_fd.txt', 'w') as f:\n",
    "    f.write(sample_recap)\n",
    "\n",
    "with open('sample_transcript_fd.txt', 'w') as f:\n",
    "    f.write(sample_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a random row from the DataFrame\n",
    "sample_row = tms_df.sample(1)\n",
    "\n",
    "# Get the recap and transcript from the sampled row\n",
    "sample_recap = sample_row['Recap'].values[0]\n",
    "sample_transcript = sample_row['transcript_joined'].values[0]\n",
    "\n",
    "# Write the recap and transcript to separate text files\n",
    "with open('sample_recap_tms.txt', 'w') as f:\n",
    "    f.write(sample_recap)\n",
    "\n",
    "with open('sample_transcript_tms.txt', 'w') as f:\n",
    "    f.write(sample_transcript)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "long-doc-summ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
