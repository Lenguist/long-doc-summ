{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Number of GPUs: 4\n",
      "Current GPU: 0\n",
      "GPU Name: NVIDIA TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available. PyTorch is using the CPU.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80.5"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('/home/mb5018/long-doc-summ/fd-summaries.json', 'r') as f:\n",
    "    summaries_data = json.load(f)\n",
    "\n",
    "# Extract the summaries into a list\n",
    "fd_summaries = [sample['summary'] for sample in summaries_data['samples']]\n",
    "\n",
    "# Now summaries_list contains the list of summaries\n",
    "average_length = sum(len(summary.split()) for summary in fd_summaries) / len(fd_summaries)\n",
    "average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "223.85"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Read the JSON file\n",
    "with open('/home/mb5018/long-doc-summ/tms-summaries.json', 'r') as f:\n",
    "    summaries_data = json.load(f)\n",
    "\n",
    "# Extract the summaries into a list\n",
    "tms_summaries = [sample['summary'] for sample in summaries_data['samples']]\n",
    "\n",
    "# Now summaries_list contains the list of summaries\n",
    "average_length = sum(len(summary.split()) for summary in tms_summaries) / len(tms_summaries)\n",
    "average_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (3.8.1)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from nltk) (2023.6.3)\n",
      "Requirement already satisfied: joblib in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from nltk) (1.3.1)\n",
      "Requirement already satisfied: tqdm in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: click in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from nltk) (8.1.6)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from click->nltk) (6.7.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (3.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /home/mb5018/long-doc-summ/myenv/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->click->nltk) (4.7.1)\n",
      "\u001b[33mWARNING: You are using pip version 20.1.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/home/mb5018/long-doc-summ/myenv/bin/python -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mb5018/long-doc-summ/gpt4_summaries/dr.-jekyll-and-mr.-hyde/2/summary-snac.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 3it [00:04,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mb5018/long-doc-summ/gpt4_summaries/dr.-jekyll-and-mr.-hyde/4/summary-snac.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 3it [00:04,  1.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mb5018/long-doc-summ/gpt4_summaries/dr.-jekyll-and-mr.-hyde/7/summary-snac.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 2it [00:02,  1.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mb5018/long-doc-summ/gpt4_summaries/dr.-jekyll-and-mr.-hyde/8/summary-snac.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 3it [00:03,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/mb5018/long-doc-summ/gpt4_summaries/dr.-jekyll-and-mr.-hyde/9/summary-snac.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 3it [00:03,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "summaries = []\n",
    "\n",
    "# Replace 'your_folder' with the path to the main folder containing the subfolders\n",
    "for filename in glob.glob('/home/mb5018/long-doc-summ/gpt4_summaries/dr.-jekyll-and-mr.-hyde/**/summary.txt', recursive=True):\n",
    "    with open(filename, 'r') as file:\n",
    "        content = file.read()\n",
    "    print(filename[:-4]+\"-snac.txt\")\n",
    "    with open(filename[:-4]+\"-snac.txt\", \"w\") as f:\n",
    "      for el in pipeline(content):\n",
    "        f.write(str(el)+\"\\n\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NEEDS EDITING\n",
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def write_tsv(text, output_file, segment_size):\n",
    "    with open(output_file, 'w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file, delimiter='\\t')\n",
    "        writer.writerow(['id', 'context', 'sentence'])\n",
    "\n",
    "        # Splitting the text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Looping through the sentences to create the context dynamically\n",
    "        context = ''\n",
    "        segment = []\n",
    "        for index, sentence in enumerate(sentences):\n",
    "            segment.append(sentence)\n",
    "\n",
    "            # Check if segment is complete\n",
    "            if len(segment) == segment_size:\n",
    "                writer.writerow([index, context.strip(), ' '.join(segment)])\n",
    "                context += ' ' + ' '.join(segment)\n",
    "                segment = []\n",
    "\n",
    "        # Writing any remaining sentences if they don't form a complete segment\n",
    "        if segment:\n",
    "            writer.writerow([index, context.strip(), ' '.join(segment)])\n",
    "\n",
    "# Text input\n",
    "text = \"\"\"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since. Whenever he feels like criticizing anyone, he should remember that all people in the world haven't had the advantages he has. Hardy lives at West Egg, the less fashionable of the two, and his house is an eyesore, but it has a view of the water and the comforting proximity of millionaires. One evening, Hardy drives over to East Egg to see two old friends, Tom Buchanan and Daisy. Tom and Daisy stroll back into the library as if to a vigil beside a perfectly tangible body.\"\"\"\n",
    "\n",
    "# Segment sizes\n",
    "segment_sizes = [2, 3, 4]\n",
    "\n",
    "# Creating the files for different segment sizes\n",
    "for size in segment_sizes:\n",
    "    output_file = f'sample_{size}_sentences.tsv'\n",
    "    write_tsv(text, output_file, size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': 0,\n",
       "  'context': '',\n",
       "  'sentence': \"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since.\"},\n",
       " {'id': 1,\n",
       "  'context': \"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since.\",\n",
       "  'sentence': \"Whenever he feels like criticizing anyone, he should remember that all people in the world haven't had the advantages he has.\"},\n",
       " {'id': 2,\n",
       "  'context': \"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since. Whenever he feels like criticizing anyone, he should remember that all people in the world haven't had the advantages he has.\",\n",
       "  'sentence': 'Hardy lives at West Egg, the less fashionable of the two, and his house is an eyesore, but it has a view of the water and the comforting proximity of millionaires.'},\n",
       " {'id': 3,\n",
       "  'context': \"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since. Whenever he feels like criticizing anyone, he should remember that all people in the world haven't had the advantages he has. Hardy lives at West Egg, the less fashionable of the two, and his house is an eyesore, but it has a view of the water and the comforting proximity of millionaires.\",\n",
       "  'sentence': 'One evening, Hardy drives over to East Egg to see two old friends, Tom Buchanan and Daisy.'},\n",
       " {'id': 4,\n",
       "  'context': \"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since. Whenever he feels like criticizing anyone, he should remember that all people in the world haven't had the advantages he has. Hardy lives at West Egg, the less fashionable of the two, and his house is an eyesore, but it has a view of the water and the comforting proximity of millionaires. One evening, Hardy drives over to East Egg to see two old friends, Tom Buchanan and Daisy.\",\n",
       "  'sentence': 'Tom and Daisy stroll back into the library as if to a vigil beside a perfectly tangible body.'}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "def preprocess(text):\n",
    "        out = []\n",
    "        # Splitting the text into sentences\n",
    "        sentences = sent_tokenize(text)\n",
    "\n",
    "        # Looping through the sentences to create the context dynamically\n",
    "        context = ''\n",
    "        for index, sentence in enumerate(sentences):\n",
    "            out.append({\"id\":index, \"context\":context.strip(), \"sentence\":sentence})\n",
    "            context += ' ' + sentence\n",
    "        return out\n",
    "\n",
    "text = \"\"\"In his younger years, Hardy's father gave him advice that he has been turning over in his mind ever since. Whenever he feels like criticizing anyone, he should remember that all people in the world haven't had the advantages he has. Hardy lives at West Egg, the less fashionable of the two, and his house is an eyesore, but it has a view of the water and the comforting proximity of millionaires. One evening, Hardy drives over to East Egg to see two old friends, Tom Buchanan and Daisy. Tom and Daisy stroll back into the library as if to a vigil beside a perfectly tangible body.\"\"\"\n",
    "\n",
    "preprocess(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_206982/2729111970.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m \u001b[0mval_data_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_data_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'example' is not defined"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import os\n",
    "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler, WeightedRandomSampler\n",
    "from tqdm.auto import tqdm\n",
    "import csv\n",
    "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
    "from transformers import (\n",
    "    T5Tokenizer,\n",
    "    T5ForConditionalGeneration,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    "    set_seed,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "softmax_func = nn.Softmax(dim=1)\n",
    "\n",
    "model_name_or_path = \"/home/mb5018/long-doc-summ/snac-main/t5-span\"\n",
    "max_length = 1024\n",
    "per_device_eval_batch_size = 8\n",
    "\n",
    "def load_dataset(data_file):\n",
    "    reader = csv.DictReader(open(data_file), delimiter='\\t')\n",
    "    examples = [row for row in reader]\n",
    "    return examples\n",
    "\n",
    "\n",
    "def evaluate(model, eval_dataloader, tokenizer):\n",
    "    model.eval()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for step, batch in tqdm(enumerate(eval_dataloader), desc='Evaluation'):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, attention_mask = batch[0], batch[1]\n",
    "        inp = {'input_ids': input_ids, 'attention_mask': attention_mask}\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(**inp, max_length=80)\n",
    "            predictions_gen = [tokenizer.decode(outputs[i], skip_special_tokens=False) for i in range(outputs.shape[0])]\n",
    "\n",
    "            for inp, p in zip(input_ids, predictions_gen):\n",
    "                inp = tokenizer.decode(inp, skip_special_tokens=False).replace('<pad>', '').strip()\n",
    "                p = p.replace('<pad>', '').strip()\n",
    "                results.append({\n",
    "                    'input': inp, \n",
    "                    'prediction': p\n",
    "                })\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "\n",
    "def process_data(data_raw):\n",
    "        texts = []\n",
    "        for row_idx, row in enumerate(data_raw):\n",
    "            #print(row)\n",
    "            text_temp = ' '.join(row['context'].split()[-int(0.9 * max_length):]) + \\\n",
    "                        ' <extra_id_0> ' + row['sentence']\n",
    "            texts.append(text_temp)\n",
    "\n",
    "        texts = tokenizer(texts, max_length=max_length, truncation=True,\n",
    "                          padding='max_length', return_tensors='pt')\n",
    "\n",
    "        input_ids, attention_mask = texts.input_ids, texts.attention_mask\n",
    "        dataset = TensorDataset(input_ids, attention_mask)\n",
    "        return dataset\n",
    "\n",
    "\n",
    "\n",
    "val_data_raw = example\n",
    "print(len(val_data_raw))\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
    "\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "\n",
    "eval_dataset = process_data(val_data_raw)\n",
    "eval_sampler = SequentialSampler(eval_dataset)\n",
    "eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=per_device_eval_batch_size)\n",
    "\n",
    "results = evaluate(model, eval_dataloader, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(model_name_or_path)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name_or_path)\n",
    "device = 'cuda'\n",
    "model.to(device)\n",
    "  \n",
    "  \n",
    "def pipeline(text):\n",
    "  example = preprocess(text)\n",
    "  val_data_raw = example\n",
    "\n",
    "  eval_dataset = process_data(val_data_raw)\n",
    "  eval_sampler = SequentialSampler(eval_dataset)\n",
    "  eval_dataloader = DataLoader(eval_dataset, sampler=eval_sampler, batch_size=per_device_eval_batch_size)\n",
    "\n",
    "  results = evaluate(model, eval_dataloader, tokenizer)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 1it [00:00,  1.12it/s]\n",
      "Evaluation: 2it [00:02,  1.26s/it]\n",
      "Evaluation: 1it [00:01,  1.18s/it]\n",
      "Evaluation: 1it [00:01,  1.22s/it]\n",
      "Evaluation: 1it [00:00,  1.07it/s]\n",
      "Evaluation: 1it [00:00,  3.92it/s]\n",
      "Evaluation: 1it [00:00,  1.26it/s]\n",
      "Evaluation: 1it [00:00,  1.84it/s]\n",
      "Evaluation: 1it [00:00,  2.46it/s]\n",
      "Evaluation: 1it [00:01,  1.23s/it]\n",
      "Evaluation: 1it [00:00,  4.53it/s]\n",
      "Evaluation: 1it [00:00,  1.01it/s]\n",
      "Evaluation: 1it [00:00,  1.51it/s]\n",
      "Evaluation: 2it [00:03,  1.56s/it]\n",
      "Evaluation: 1it [00:00,  2.11it/s]\n",
      "Evaluation: 1it [00:00,  2.60it/s]\n",
      "Evaluation: 2it [00:02,  1.18s/it]\n",
      "Evaluation: 1it [00:00,  1.01it/s]\n",
      "Evaluation: 1it [00:01,  1.04s/it]\n",
      "Evaluation: 1it [00:00,  1.26it/s]\n"
     ]
    }
   ],
   "source": [
    "all_fd_results = []\n",
    "for summary in fd_summaries:\n",
    "  all_fd_results.append(pipeline(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluation: 1it [00:01,  1.64s/it]\n",
      "Evaluation: 3it [00:04,  1.41s/it]\n",
      "Evaluation: 2it [00:03,  1.65s/it]\n",
      "Evaluation: 2it [00:02,  1.33s/it]\n",
      "Evaluation: 2it [00:02,  1.04s/it]\n",
      "Evaluation: 4it [00:05,  1.26s/it]\n",
      "Evaluation: 1it [00:00,  1.19it/s]\n",
      "Evaluation: 4it [00:06,  1.57s/it]\n",
      "Evaluation: 3it [00:05,  1.68s/it]\n",
      "Evaluation: 1it [00:01,  1.55s/it]\n",
      "Evaluation: 4it [00:05,  1.30s/it]\n",
      "Evaluation: 2it [00:03,  1.62s/it]\n",
      "Evaluation: 2it [00:03,  1.68s/it]\n",
      "Evaluation: 1it [00:01,  1.30s/it]\n",
      "Evaluation: 2it [00:04,  2.21s/it]\n",
      "Evaluation: 4it [00:06,  1.58s/it]\n",
      "Evaluation: 3it [00:04,  1.38s/it]\n",
      "Evaluation: 6it [00:09,  1.56s/it]\n",
      "Evaluation: 1it [00:01,  1.31s/it]\n",
      "Evaluation: 4it [00:05,  1.38s/it]\n"
     ]
    }
   ],
   "source": [
    "all_tms_results = []\n",
    "for summary in tms_summaries:\n",
    "  all_tms_results.append(pipeline(summary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average # of Coherence Errors: 11.1\n",
      "Average % Coherence Errors: 71.91664658440973%\n"
     ]
    }
   ],
   "source": [
    "results = all_tms_results\n",
    "\n",
    "total_coherence_errors = 0\n",
    "total_percentage_errors = 0\n",
    "total_passages = len(results)\n",
    "\n",
    "for passage in results:\n",
    "    coherence_errors = 0\n",
    "    total_predictions = len(passage)\n",
    "    \n",
    "    for prediction_dict in passage:\n",
    "        if prediction_dict['prediction'].startswith('false'):\n",
    "            coherence_errors += 1\n",
    "    \n",
    "    percentage_errors = (coherence_errors / total_predictions) * 100\n",
    "    total_coherence_errors += coherence_errors\n",
    "    total_percentage_errors += percentage_errors\n",
    "\n",
    "average_coherence_errors = total_coherence_errors / total_passages\n",
    "average_percentage_errors = total_percentage_errors / total_passages\n",
    "\n",
    "print(f\"Average # of Coherence Errors: {average_coherence_errors}\")\n",
    "print(f\"Average % Coherence Errors: {average_percentage_errors}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stick to TMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_205799/1083334760.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Sample data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m data = [\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m\"In his younger years, Hardy's father...\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"false<extra_id_0> character Hardy</s>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    (\"In his younger years, Hardy's father...\", \"false<extra_id_0> character Hardy</s>\"),\n",
    "    (\"In his younger years, Hardy's father...\", \"true</s>\"),\n",
    "    (\"In his younger years, Hardy's father...\", \"false<extra_id_0> scene</s>\"),\n",
    "    (\"In his younger years, Hardy's father...\", \"false<extra_id_0> character Tom Buchanan Daisy</s>\"),\n",
    "    (\"In his younger years, Hardy's father...\", \"true</s>\")\n",
    "]\n",
    "\n",
    "# Function to interpret the result\n",
    "def interpret_result(text, prediction):\n",
    "    if \"true\" in prediction:\n",
    "        return \"Coherent\"\n",
    "    elif \"character\" in prediction:\n",
    "        return \"New Character without Introduction\"\n",
    "    elif \"scene\" in prediction:\n",
    "        return \"Abrupt Scene Transition\"\n",
    "    else:\n",
    "        return \"Unknown Error\"\n",
    "\n",
    "# Storing the interpretation\n",
    "interpretations = [interpret_result(text, prediction) for text, prediction in data]\n",
    "\n",
    "# Counting the occurrences for visualization\n",
    "interpretation_counts = {interpretation: interpretations.count(interpretation) for interpretation in set(interpretations)}\n",
    "\n",
    "# Plotting\n",
    "plt.bar(interpretation_counts.keys(), interpretation_counts.values())\n",
    "plt.title('Interpretation of Predictions')\n",
    "plt.xlabel('Error Types')\n",
    "plt.ylabel('Frequency')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
